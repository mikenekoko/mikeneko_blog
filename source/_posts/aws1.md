---
title: AWS勉強会1日目
date: 2020-07-02 16:32:06
tags:
---

# コンテナ入門(60分)
* モノリスとは
* コンテナとは
* コンテナオーケストレーション
* イメージレジストリ、コンテナ実行環境
* その他のコンテナ関連サービス
* 現実世界のコンテナワークロード
* ベストプラクティス

## モノリスとは？
シンプルなアプリケーションを想像してみて。
LB -> App -> DB
Appがでかくなって、障害が出てきたとする。
一部が動かないとか、重くなるとか。
開発者が、それをみてマイクロサービス化しよう！と思うとする。
その瞬間、モノリスと呼ばれるようになる。
モノリスという故障に込められるニュアンスは、
* 関係者間調整のオーバーヘッド
  * 1つのアプリケーションに対して色々詰め込みすぎると、他の人の開発待ちでリリースできないとか。
  * 細かいリリースをしていくことが難しくなる。
  * 1回のデプロイの量が増えて、影響範囲が増えてくるのでそれによりまた障害が発生する
  * それによる影響範囲の広さがある
* モジュール構造維持の難しさ
* 非効率なスケーリング
  * 不要なものまでスケーリングされる
* テスト・ビルドに要する時間の長さ
  * たった1行変更するだけなのに、全部ビルドし直すから1時間かかるとか。。

そういうものを解決するためにマイクロサービス化を期待する
* 変更による影響範囲の局所化
* モジュール境界の維持しやすさ
* 独立したデプロイとスケーリング
* 独立的なチーム夜開発・運用
  * 独立させることができるので、一部だけ言語を分ける、フレームワークを変えるなどが可能
  * ずっとレガシーを使い続けなければいけないという状況から、別の言語を使える選択肢ができる！

## コンテナとは？
コンテナの話に入る前に、アプリケーションを構成するコンポーネントを見てみます
1. ランタイム/エンジン(javaであればJVMとか)
2. アプリケーションコード
3. 設定ファイル
4. 依存ライブラリ/パッケージ
ローカル環境 / テスト環境 / 本番環境を考えると…
ランタイムは各環境にそれぞれインストールされていますよね？
本番環境だけバージョンが低いとか。
そういうのを解決するための策として、コンテナがあります！
環境で設定されているものを全て1コンテナに集約させる
`ランタイム/エンジン + 依存ライブラリ/パッケージ + アプリケーションコード = コンテナ`
設定ファイルは入ってないですよね？はい、入れていないのです。
それを入れてしまうと環境ごとに変えることができなくなってしまいますからね。
設定ファイル以外を合体させるのです。
Dockerがデファクトスタンダードです。
各環境でインストールしていたエンジンを、コンテナで動かすようにします。
全部同じコンテナを、Dockerで動かします。

コンテナとは？
一言で言えば、リソース隔離されたプロセス
普通にサーバーに立てるとしたら、サーバーのOSがあって、動くハードウェアがあって。

ホスト型
* ソフトウェア毎に仮想環境を動かす仮想化ソフトがあって、その上で仮想環境を立ててその中でも更にOSが立つ
ハイパーバイザー型
* EC2みたいなハイパーバイザー型だとOSを選ぶけど、それはVMの中のOSであってサーバー自体のOSではないです。
* `インフラストラクチャ -> OS -> ハイパーバイザー -> VM`

コンテナ
* コンテナは、1つのOS上で複数同時稼働可能であり、各コンテナ内で独立したルートファイルシステムやCPU・メモリ、プロセス空間などを利用可能
* ハードウェアの仮想化である仮想マシン(VM)とは異なる
* コンテナというのは、マシンができるというよりはプロセスができるだけ。
* `インフラストラクチャ -> OS -> コンテナエンジン -> コンテナ`

コンテナの特徴とメリット
* 再現用意性
  * 削除再生が簡単
* 可搬性
  * HWやOWを抽象化
* リソース効率
  * オーバーヘッドが少ない
  * 粒度を細かく利用率の向上が可能
* スピード
  * 起動が非常に高速

コンテナにおけるキーコンポーネント
* コンテナ
  * プロセスとして起動するアプリの実行環境
  * イメージを持とに起動
* イメージ
* コンテナエンジン
* レジストリ
* Dockerfile

Dockerイメージ
* コンテナを起動するテンプレートとして利用される
  * 基本イメージ(OS)の上に、ライブラリやアプリケーションコードを追加していく
  * 読み取り専用のため、書き換えは不可能
  * コンテナとして起動すると、アタラタに一つレイヤーが追加されそこだけ編集可能になる

Dockerを利用した基本的ワークフロー
* `dockerfile` を利用して、ビルドする
* `docker build` でビルドする
* コンテナイメージを作成

既にイメージがある場合
* `docker run` でコンテナを起動。中で作業する
* `docker commit` でイメージを作成する

イメージをアップロードする
* `docker push` して、レジストリにイメージをアップロードする

イメージを使いたい
* `docker pull` でイメージを取得する
* 使いたい環境でそれぞれ起動すれば、同じイメージで起動できる！

## コンテナオーケストレーション
思ったより面倒じゃない？
dockerの責務は、同一サーバー上のコンテナライフサイクル管理であって、複数サーバーやコンテナを束ねた概念は別に者に任せているよ。
で、
AmazonECSというのを使うと、
* 「このEC2インスタンスのクラスタでコンテナを実行したいです」
* 「このコンテナの3つをAZに分散させて10個でプロイしてこのLBにつなげて下さい」みたいな命令もできるよ！

### AmazonElasticContainerService (ECS)
* クラウドでコンテナを本番環境利用するためのオーケストレーター
* AWSのサービスなため、各種AWSサービスとの高度な連携が可能
* 数億コンテナ/週 数百万EC2インスタンスを管理するスケーラビリティー
* 多彩なワークロードをサポートするタスクサービスというシンプルなリソース表現
* Linux , Windowsなど幅広くサポート

### AmazonElasticKubernetesService (EKS)
* 運用難易度の高いKubernetesマスターをマネージドで提供する
* エコシステムのOSSやツールを利用できる。CNCFから認可を貰えている（簡単に今のKubernetesサービスから移行できる）
* 各種AWSサービスとの連携
* EKSサービスチーム、OSSチームによるKubernetesコミュニティへの貢献をしている
* オープンソースなため、何か問題が起きた場合にソースコードを直接見ることもできる！

### ElasticContainerRegisttry (ECR)
ECSやEKSに対して命令を送ったとして、どこからイメージを取っている？ -> ECRからとってるよ
* フルマネージドなプライベーコンテナイメージレジストリ
* セキュアである。保管イメージの自動的な暗号化、IAM連携
* スケーラブルかつ高い可用性がある
  * 100台あれば、100台同時にpullが走りますよね？そういうものにもスケーリングして対応できます。
* Docker CLIからの利用も可能
* ECS/EKS/Kubernetesだけでなく、その他のコンテナオーケストレーターからも利用可能
* ライフサイクルポリシーでイメージの自動クリーンアップも可能
  * 不要な古いイメージは消してくれるよ！

### AWS Fargate
AWSマネージド
* EC2のインスタンスのプロビジョン、スケール、管理不要
  * 仮想マシン自体の運用が不安になるよ！

コンテナネイティブ
* 仮想マシンを意識しないシームレスなスケーリング
* コンテナの起動時間・仕様リソースに応じた料金設定
* AWSサービスとの連携
* Fargateはイメージをキャッシュしないので、イメージが大きいと起動が遅くなる

やってみたとしたら
* 「このコンテナの3つをAZに分散させて10個でプロイしてこのLBにつなげて下さい」 という命令をECSに送る
* Fargateがそれを受け取って実行
* ECRからイメージを取得して即座に実行
面倒なクラスタの管理とかを全部Fargateがやってくれる！

### AWS Cloud Map
クラウドリソースのためのサービスディスカバリ
* 各リソースに対する継続的なヘルスチェック
* ディスカバリ対象サービスの変更に合わせた動的な更新

開発生産性の向上
* 全アプリケーションリソースをディスカバリ可能な単一のレジストリ
* ユーザーフレンドリーな名前の設定が可能

### AWS App Mesh
ログやメトリクスなどの出力を可能
サービスメッシュ

### Amazon CloudWatch Container Insights
* ダッシュボードを見れるようにする。StackDriverみたいなイメージ
* コンテナワークロードのためのモニタリングサービス。
* 自動ダッシュボードによる可視化、フィルタリングが可能

## コンピューティングの多彩な選択肢
EC2
* カスタマイズ性が広く、できることが多く運用が大変である

Lambda
* 関数実行環境。サーバーレス。

Fargate
* これは上記2つの中間みたいなイメージ

Functions - Containers - VirtualMachines

## コンテナにフィットする開発とは？
The Twelve-Factor App などに詳しく書いてある
一部抜粋
* 1つのコンテナで起動するプロセスは1つにする
  * Nginx + Apache Httpd は、NginxコンテナとApacheHttpdコンテナに分割させる
* ログは標準出力・標準エラー出力にする
  * ログドライバーの機能を利用して収集する
* コンテナ内部に状態を持たせない
  * RDBMSやS3のような外部ストレージに保持する
* Dockerイメージの最小化
  * 不要なパッケージは含めずに、デプロイを高速化する
* 設定ファイルではなく環境変数を利用する
  * 環境ごとにコンテナ分けるのはNG
* SSHを避けるというメンタルモデル
  * どこでコンテナが動いているかわからない状態が健全な状態と考える
  * デバッグ・運用に必要な情報はログとして吐き出して収拾する。SSHする必要がないようにする。
* 継続的にデプロイする
  * 小さな変更を高速度にデプロイ氏、差異を最小に留める
  * デプロイそのものへの心理的安全性を高める
* 全てを自動化する
  * 可能な限り自動化する方法を考える。
  * CIなどのパイプラインによるリリース
* リソース使用率と予約率によるスケーリング
  * 使用率でコンテナを
  * 予約率でホストマシンのスケーリングを行う
* AWS Fargate 利用の検討
  * 仮想マシンなしにコンテナを実行できるFargateを利用すれば、仮想マシン自体の運用が不要になる
* コンテナ実行環境の仮想マシンは `ペット` ではなく `家畜`
  * 特殊な設定を施した特別な仮想マシンを使わない
  * 簡単に置き換えが可能な仮想マシンを並べる
  * 手厚く見守って運用という考えをやめる
    * ペット
      * 従来型の運用
      * サーバーに色々インストール、見守る
      * 手厚い管理が必要
    * 家畜
      * クラウド型の運用
      * 使い捨て
      * 死んだら終わりでいい

# アプリのステートレス化をしよう
* コンテナの中に入れるのはステートレスなアプリとする
* ステートが必要なものはコンテナの外に置く
  * RDMBSが必要 -> Amazon RDS
  * オブジェクトの保存場所が欲しい -> Amazon S3
そのため、既存アプリをクラウド化させる場合対応させる開発が必要になる。
ちなみに、ステートとは `状態` を意味する
* ステートレスとは、状態を持たない。たとえば、コンテナ内にキューを持つとかそういうのは一切なし。
* コンテナ内に直接状態を持たないことで、他のコンテナからでも同じ作業ができる。

# CICDパイプライン
アプリのコード変更〜コンテナのデプロイを管理する
* 自動化することで誰がやっても同じ用にデプロイ可能
* ビルドはもちろん、単体テストや総合テスト、負荷テストも通す
* カナリアデプロイやリージョンデプロイなども可能
  * カナリアテストとは、一部だけリリースして影響を見ること。ABテストみたいな
* 途中にマニュアルでの承認を挟むことも可能
`AWS CodePipeLine` / `AWS Code Build` という2サービスを使う

source
* AWS CodeCommit

Build
* AWS CoeBuild

Deploy
* AWS CodePipeLine

EC2の上にコンテナを立てることができる
それを管理するのが、ECS、EKS。
EC2を運用したくない場合、Fargateを使うと上に乗っかるコンテナだけ利用することができる！
今回はECSについて詳しく説明します。

# AmazonECSの概念
* Task
  * 実態。コンテナ
* Task Definition
  * タスクの定義
  * どんなコンテナか、どんな設定かというもの
* Cluster
  * Taskが走るインスタンスの集合体。
  * Fargateとか、EC2とか
* Manager
  * ClusterのリソースとTaskの状態を管理
* Scheduler
  * Clusterの状態を見てTaskの配置を行う
* Agent
  * EC2インスタンスとManagerの連携を司る

## Cluster
* タスク/サービスの論理的なグループを作る
  * リージョンごとに作成
  * クラスター別にリソースを分ける
* EC2を利用する場合、コンテナインスタンスのグループ
* IAMポリシーによるアクセス許可/制限

## Task
* Task Definitionの情報から起動する
  * family:revisionで指定
* 一つ以上のコンテナを実行しているリソースそのもの
* CPUとメモリの上限を指定する
  * それをもとにスケジュールされる

## Service
Scheduler
* ロングランニングアプリケーション（Taskの数）を希望数に保つ
* Task Definition を新しくしてデプロイ
  * Blue／Greenデプロイ（Blueの状態のコンテナから、Greenのものに切り替えていくという安全なデプロイ）
* ELBと連携することも可能
* メトリクスに応じてTask数のAutoScalingも可能

動的ポートマッピング
* ALBの前に挟む
+ 空いているコンテナを探して、それに対してマッピングさせるように動的に割り当てる
* ユーザーは、LB経由でマッピングされたコンテナにアクセスできるようになる

追加リソースなしの更新
* 今の通信はそのままうけて、加減50% 上限50%だとした場合に50%を保つように今の古いインスタンスをそのまま起動しておく
* 深夜とかにリクエストが減った場合に、新しいコンテナに50%のリソースを保ったまま移行させることができる
* これがBlud/Greenデプロイ

2倍のリソースを使った更新
* 一時的に、今あるコンテナ上に新しい更新後のコンテナを立てて、古いコンテナへのリクエストが処理し終わったタイミングで移行させることもできる
* 一時的に空き容量をかなり奪うことにはなる

# ECS Cluster と EC2 Auto Scaling
オートスケーリングしたい場合
* クラスタの作成
* ASG（Auto Scaling Group)の作成
* インスタンス軍の起動
* タスクの実行
そこを全部管理するのは大変！

## ECS Capacity Providers + ECS Cluster Auto Scaling
ECS TASKを6つ欲しいという場合、インスタンスがいくつ欲しいかを判断して設置することができる

### ECS Capacity Providers
* タスクの配置先を決定するための新しい方法
* タスク配置先の柔軟なコントロールが可能に
* ECとFargateの双方で利用が可能
* weight を決めることができる。どちらにTaskをよらせるかどうか。
  * Task6を要求し、 weight が 5と1なら、それぞれ5台と1台立てる。片方に寄らせることができる
* baseというものを使うことができる。最低値、基本の値。最小タスク数
  * 6台もとめられたら、まずbaseで配置したあとにweightで割り振る。

ネットワークモード
* awsvpc
  * タスクにNICを割り振ることができる
  * それにより、タスクごとにENIを自動割当が可能になる（通ってOKな通信）
* タスク内のコンテナはlocalhostを共有
* VPC内の他リソースへPrivateIPで通信が可能

コンテナのログやメトリクスの監視
* awslogs log driver がログを Amazon CloudWatch Logsに送る
* ECS AgentがメトリクスをAmazonCloudWatchに送る

コンテナから複数のログを異なる場所におくる方法
* 後処理で分割する
* `SidecarLogger` を使う
  * アプリケーションコンテナはログを一次共有ボリュームに書き込む
  * Sidecarコンテナがそのボリュームから異なる場所にログを転送する
  * FireLensによるカスタムログルーティングもこれに該当

# Fargate Spot
* AWS Fargateで中断処理に強いワークロードを実行するための新しいオブジェクト
* 通常のFargateの価格と比較して最大70%の割引
* CapacityProviderのFargateSpotキャパシティとして利用可能

ECSClusterを作成
* Capacity ProviderでFARGET_SPOTを予め指定して作成
* MC画面からFargateを指定して作成するとFargate,Fargate＿SPOTのCapacityProviderがClusterに紐付いている

Taskの中断について
* AWSにキャパシティが必要になった時、FargetSpotで稼働するタスクは2分前の通知とともに中断される
* 安い理由
* 中断イベントをAmazonEventBridgeとかで取得して対応とかもできる。
* SIGTERMシグナルが来た場合に、安全に終了する処理の開発が必要になる
  * 中断するまえにスナップショット取って、再開時にそこから再開する仕組みとか。
1日目はここまで。